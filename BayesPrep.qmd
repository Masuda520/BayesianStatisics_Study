---
title: "ベイズ統計学事前準備"
format: 
 html:
  theme: default
  toc: true
  toc-title: 目次
  number-sections: false
  self-contained: true
  coe-tools: true
  code-fold: true
  # embed-resources: true
  # self-contained-math: true
execute: 
 error: false
 warning: false
author: Riku Masuda
---

## この文書について  
ベイズ統計学の本を読む際に、事前に知っておいた方が良いベイズ統計の基本的な考え方・ノーテーションについて簡単にまとめたものです。  

## 同時確率分布・周辺確率分布・条件付き確率分布    
いきなりベイズ統計学の話に入る前に、確率分布に関わる基本用語をおさらいします。  

### 同時確率分布  
二つの確率変数$y,\theta$を考えます。  
$y$が確率変数なら、小文字ではなく大文字の$Y$で表すべきでは？　と思うかもしれませんが、**ベイズ統計学では確率変数なのか実測値なのかについて、大文字・小文字での区別をつけないことが多い**ため、この文書でもあまり区別しないことにします。  
$y$と$\theta$は互いに相関しているとします。具体的には、相関係数$\rho = 0.9$であるような2次元の多変量正規分布にしたがっているとします。ただし、$y,\theta$は両方とも、平均と分散がそれぞれ0,1だとします。  
これを数式で表すと以下のようになりました。  
$$
\begin{pmatrix}
   y \\
   \theta
\end{pmatrix} \sim 
N_2 \left(\begin{pmatrix}
   0 \\
   0
\end{pmatrix} , \begin{pmatrix}
   1 \ \ 0.9 \\
   0.9 \ \ 1
\end{pmatrix} \right) 
$$

Rを使って乱数$(y,\theta)$を500個生成して、散布図を描いてみます。  
```{r}
pacman::p_load(tidyverse,mvtnorm,ggExtra)
mu = c(0,0) ; Sigma = matrix(c(1,0.9,0.9,1),nrow=2,ncol=2 )
data = rmvnorm(n = 500 , mean = mu , sigma = Sigma ) %>%
  tibble(y = .[,1] , theta = .[,2])
data %>%
  ggplot(aes(x = theta ,  y = y) ) + 
  geom_point() + 
  theme_minimal()
```

横軸$\theta$と縦軸$y$には正の相関関係があるとわかります。  
複数の確率変数が同時に生成されるとき、それが従う確率分布のことを、同時確率分布と呼んだのでした。  
二つの確率変数$y,\theta$の同時確率分布の確率密度関数を、$p(y,\theta)$と書くことにします。$p(y,\theta)$のことを、同時確率密度関数や、同時密度関数と呼びます。  
多変量正規分布$p(y,\theta)$の具体的な関数形は煩雑なのでここでは省略しますが、確率密度の値についてはmvtnormパッケージのdmvnorm()関数を用いれば計算できます。  
```{r}
#| code-fold: false
## y=0,theta=0の密度
dmvnorm(c(0,0) , mean = mu , sigma = Sigma)
## y=2,theta=2の密度
dmvnorm(c(2,2) , mean = mu , sigma = Sigma)
```

これを式で表すと、
$$
p(y=0,\ \theta=0) =  0.1837763,\ \ \  p(y=2,\ \theta=2)=0.01276941
$$

となります。(厳密に言うなら小数点レベルでは異なります)  
$Y,\theta$は正の相関を持つので、$y=2,\theta=-2$のような組み合わせはとても珍しいものとなり、確率密度$p(y=2,\theta=-2)$は小さくなります。  

```{r}
#| code-fold: false
## y=2,theta=-2の密度
dmvnorm(c(2,-2) , mean = mu , sigma = Sigma)
```

ベイズ統計学では、確率分布のことをその確率密度関数で表現してしまうことが多いです。  
つまり、
$$
\begin{pmatrix}
   y \\
   \theta
\end{pmatrix} \sim p(y,\theta)
$$

と書いてしまいます。  

### 周辺確率分布  
さきほど、確率変数$y,\theta$は同時確率分布$p(y,\theta)$にしたがっていました。  
このうち、$\theta$を無視して、$y$の分布だけに着目してみます。  
```{r}
data %>%
  ggplot(aes(x = y)) + 
  geom_histogram(aes(y = after_stat(density)), fill = "blue") + 
  geom_density(alpha = 0.3, fill = "red") + 
  labs(title = "yのヒストグラムと密度関数", x = "y", y = "密度") + 
  theme_minimal()
```

$y$の従う分布は平均0分散1の正規分布$N(0,1)$となります。※ここで描いた密度関数は実データ(サンプルサイズ500)を元に描いているので、正確に描いた正規分布よりも歪んでいます。  
$y$が従う分布を周辺分布（周辺確率分布）と呼びます。同様に、$y$ を無視して$\theta$が従う分布を考えた時も、これのことを周辺分布と呼びます。**周辺分布とは**、複数の確率変数の中で、**特定の変数にだけ注目したときの確率分布**のことを言うのでした。  
$y$の周辺分布に対応する密度関数のことを、$p(y)$と書きます。$p(y)$のことを、周辺確率密度関数や、周辺確率密度と呼びます。  
この書き方では、同時密度関数$p(y,\theta)$と同じく、$p$を関数の名前として使ってしまっているので、周辺密度関数と同時密度関数の区別がつかなくて問題があると思うかもしれません。実際その通りで、**単に$p(\cdot)$と書いただけでは、これが何の確率密度関数を表しているのかは、文脈からしかわかりません**。ベイズ統計学ではあまりに確率密度関数を書く機会が多いので、**区別がつかなくなるリスクを承知の上で、単に$p(\cdot)$とだけ書いて、確率密度関数を表現することが多い**です。  
先ほどと同様に、確率変数$y$が従う分布（周辺分布）を単に$p(y)$と書くことにすると、
$$
y \sim p(y)
$$

と表現できます。  

### 条件付き確率分布  
今考えている例では、散布図からもわかるように、$\theta=2$のとき$y=0$である確率は低いです。$y$と$\theta$は強く相関するので、$\theta$の値が高いときは、$y$の値も高くなるためです。    
$y$の周辺分布を考えた時は$y=0$である確率はむしろ高いくらいですが、$\theta$の値を"固定"した場合、$y$の従う確率分布は周辺分布とは異なるものとなります。  

```{r}
data %>%
  ggplot(aes(x = theta ,  y = y) ) + 
  geom_point() + 
  geom_vline(xintercept = 2 , lwd = 5 , col = "gold", alpha = 0.3) + 
  theme_minimal()
```

このように$\theta$の値が固定されたとき、言い換えれば$\theta$の値が条件付けられたときに、$y$が従う確率分布のことを条件付き確率分布と呼びます。  
条件付き確率分布の密度関数のことを条件付き確率密度関数や、条件付き密度関数と表現し、この例では$\theta$が条件付けられたときの$y$の分布を考えているので、$p(y|\theta)$と書きます。逆に、$y$が条件付けられたときの$\theta$の確率密度関数のことを、$p(\theta|y)$と書きます。  



